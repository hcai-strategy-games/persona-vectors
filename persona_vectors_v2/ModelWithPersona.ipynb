{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0d0eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from requests->transformers) (2025.10.5)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl (288 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, regex, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 regex-2025.11.3 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from torch) (2025.10.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.0-cp314-cp314-macosx_11_0_arm64.whl (74.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch]32m3/4\u001b[0m [torch]kx]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.9.0\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx>=0.27->ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9->ollama)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [ollama]2m3/5\u001b[0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 ollama-0.6.0 pydantic-2.12.4 pydantic-core-2.41.5 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60073615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.7.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-hw3/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Downloading openai-2.7.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl (318 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai]2m2/3\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.12.0 openai-2.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a744e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "from Dataset import PersonaDataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from prompts import PROMPTS\n",
    "import torch\n",
    "import ollama\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2f2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelWithPersona import ModelWithPersona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c49cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from: ./persona_dataset/sarcastic_dataset.json\n"
     ]
    }
   ],
   "source": [
    "dataset = PersonaDataset.load_dataset_from_json(trait=\"sarcastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b5b2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_persona = ModelWithPersona(target_model_id=\"microsoft/DialoGPT-small\", dataset=dataset, layer=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7c8f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_pairs = dataset.extract_pos_neg_question_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d993a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair(pos='Your responses should be witty and sarcastic when appropriate. Avoid being straightforward or overly literal.', neg='Your responses should be polite and respectful, avoiding any use of sarcasm. Ensure your language is clear and straightforward.', question='At the office party, someone mentions bringing in their favorite snacks. How would you comment on this without being too direct?')\n"
     ]
    }
   ],
   "source": [
    "print(trait_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534d01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = trait_pairs[0]\n",
    "temperature = 0.9\n",
    "max_new_tokens = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c1078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of layers: {model_with_persona.model.config.n_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63efff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Tokenizing\n",
      "Retrieved Prompt Last Activation\n",
      "generating tokens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:   6%|▋         | 4/64 [00:00<00:01, 33.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed nput Tensor: Iteration 0\n",
      "Computed Final Activation - Iteration 0\n",
      "Computed nput Tensor: Iteration 1\n",
      "Computed Final Activation - Iteration 1\n",
      "Computed nput Tensor: Iteration 2\n",
      "Computed Final Activation - Iteration 2\n",
      "Computed nput Tensor: Iteration 3\n",
      "Computed Final Activation - Iteration 3\n",
      "Computed nput Tensor: Iteration 4\n",
      "Computed Final Activation - Iteration 4\n",
      "Computed nput Tensor: Iteration 5\n",
      "Computed Final Activation - Iteration 5\n",
      "Computed nput Tensor: Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:  12%|█▎        | 8/64 [00:00<00:01, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Final Activation - Iteration 6\n",
      "Computed nput Tensor: Iteration 7\n",
      "Computed Final Activation - Iteration 7\n",
      "Computed nput Tensor: Iteration 8\n",
      "Computed Final Activation - Iteration 8\n",
      "Computed nput Tensor: Iteration 9\n",
      "Computed Final Activation - Iteration 9\n",
      "Computed nput Tensor: Iteration 10\n",
      "Computed Final Activation - Iteration 10\n",
      "Computed nput Tensor: Iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:  19%|█▉        | 12/64 [00:00<00:01, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Final Activation - Iteration 11\n",
      "Computed nput Tensor: Iteration 12\n",
      "Computed Final Activation - Iteration 12\n",
      "Computed nput Tensor: Iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:  25%|██▌       | 16/64 [00:00<00:01, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Final Activation - Iteration 13\n",
      "Computed nput Tensor: Iteration 14\n",
      "Computed Final Activation - Iteration 14\n",
      "Computed nput Tensor: Iteration 15\n",
      "Computed Final Activation - Iteration 15\n",
      "Computed nput Tensor: Iteration 16\n",
      "Computed Final Activation - Iteration 16\n",
      "Computed nput Tensor: Iteration 17\n",
      "Computed Final Activation - Iteration 17\n",
      "Computed nput Tensor: Iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:  31%|███▏      | 20/64 [00:00<00:01, 34.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Final Activation - Iteration 18\n",
      "Computed nput Tensor: Iteration 19\n",
      "Computed Final Activation - Iteration 19\n",
      "Computed nput Tensor: Iteration 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Prompt and Response Average:  38%|███▊      | 24/64 [00:00<00:01, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Final Activation - Iteration 20\n",
      "Computed nput Tensor: Iteration 21\n",
      "Computed Final Activation - Iteration 21\n",
      "Computed nput Tensor: Iteration 22\n",
      "Computed Final Activation - Iteration 22\n",
      "Computed nput Tensor: Iteration 23\n",
      "Computed Final Activation - Iteration 23\n",
      "Computed nput Tensor: Iteration 24\n",
      "Computed Final Activation - Iteration 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_last_pos, response_avg_pos = model_with_persona.get_prompt_last_and_response_average(system_prompt=pair.pos, user_prompt=pair.question, temperature=temperature, max_new_tokens=max_new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f621740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1886e+00, -2.6113e-01, -1.0395e+00,  1.5894e-01, -3.6299e-01,\n",
      "          1.0687e-01,  8.0228e-01,  1.6220e+00,  4.0334e-01, -1.9854e-01,\n",
      "         -3.5953e-01, -6.4886e-01, -5.2597e-01,  3.7021e-01,  1.5407e-01,\n",
      "          1.2293e+00, -1.1775e+00, -3.9331e-01, -9.4887e-02,  1.7115e-01,\n",
      "          4.2710e-02,  7.2632e-01, -3.3051e-01, -4.4977e-01, -3.5673e-01,\n",
      "          1.2375e-01, -1.0963e+00,  5.1758e-01, -1.2790e-01, -2.7610e-01,\n",
      "          6.3037e-01,  8.7831e-01, -9.3451e-02,  1.7544e-01, -5.8065e-01,\n",
      "         -1.1936e+00, -6.6627e-01,  6.8836e-01,  6.7629e-01,  1.0801e+00,\n",
      "          6.6307e-01, -7.5107e-01,  2.4300e-01, -1.0624e+00,  1.0986e+00,\n",
      "         -1.0079e-01, -7.9802e-02, -6.0833e-01,  3.6984e-01, -3.9252e-01,\n",
      "         -7.3035e-01,  5.7018e-02,  1.9760e-01, -1.6968e-01,  8.8764e-01,\n",
      "          1.2742e+00, -1.2445e+00, -6.8231e-01,  1.0299e+00, -1.7002e-01,\n",
      "         -1.0069e+00,  3.7557e-01, -1.1509e-01, -6.9833e-01, -1.1015e+00,\n",
      "          1.0870e+00, -1.9990e-01,  1.1399e-02,  7.7428e-01, -2.0697e+00,\n",
      "          6.0457e-01,  8.9819e-01,  5.1747e-01,  1.9471e-01, -8.4404e-01,\n",
      "         -5.9203e-01,  1.1399e-01,  6.6099e-02, -7.2604e-01,  6.5093e-01,\n",
      "         -2.3802e-01,  2.1067e-01, -4.2802e-01, -4.5079e-01, -3.6528e-01,\n",
      "         -1.6901e-03,  3.7720e-01,  1.3847e+00,  1.1165e+00, -9.9158e-01,\n",
      "          1.1411e+00,  2.9453e-01,  6.1704e-01,  4.7923e-01,  1.0781e+00,\n",
      "         -2.6689e-01,  1.2669e-01, -8.6094e-01,  6.1532e-01, -1.8840e+00,\n",
      "          2.3743e-01,  6.1813e-01,  2.7727e-01,  5.9116e-01, -3.7381e-01,\n",
      "         -7.2872e-01,  1.0307e+00,  3.4597e-01,  6.4649e-01,  1.8695e-01,\n",
      "          4.1580e-01, -7.1582e-02, -4.8716e-01,  6.9679e-01,  1.8618e-01,\n",
      "         -4.4591e-01,  3.7784e-02, -3.2412e-01,  2.0752e-01, -8.3419e-02,\n",
      "          4.2828e-01, -2.7609e-01,  9.5503e-02, -2.0036e-01,  5.3563e-01,\n",
      "          1.3097e+00,  4.8193e-01, -1.6409e+00,  8.0512e-01, -1.2058e+00,\n",
      "         -8.6705e-01,  7.1392e-01,  3.8946e-01,  4.5555e-01,  4.1537e-01,\n",
      "          2.3229e-01,  1.0873e+00, -6.3307e-01, -9.6825e-02,  3.0953e-01,\n",
      "          1.8003e-01,  6.3835e-01,  7.3783e-01,  1.7990e-01, -3.5601e-02,\n",
      "          3.3720e-01, -3.6389e-01, -4.5231e-01,  6.4476e-01, -2.7520e-01,\n",
      "          1.0613e+00,  2.3934e-01,  1.3100e+00,  6.4050e-01,  7.3891e-02,\n",
      "          6.7497e-01,  6.9317e-02,  4.0150e-01,  3.6354e-01,  9.0416e-02,\n",
      "         -2.6542e-01, -1.6062e-01, -1.0310e-01,  3.6343e-01,  9.7380e-01,\n",
      "         -3.0963e-01, -6.4811e-01, -1.9155e+00,  3.0718e-01,  5.8896e-01,\n",
      "          3.3131e-02,  1.0063e+00,  3.2226e-01,  5.4383e-01, -1.4207e-01,\n",
      "          4.6302e-01, -7.0982e-01, -6.7238e-01,  4.3086e-01,  7.2075e-02,\n",
      "         -9.6612e-01, -4.8866e-01, -1.1339e+00,  9.6700e-01, -7.3893e-01,\n",
      "          2.5671e-01, -2.1766e-01,  1.0898e+00,  1.8566e-01,  5.4137e-01,\n",
      "         -7.0695e-01, -5.2299e-01,  9.8236e-01, -3.3005e-01, -3.5243e-01,\n",
      "         -1.0416e+00,  7.1942e-01,  5.7384e-01,  4.5185e-01,  4.2896e-01,\n",
      "          5.6162e-01, -4.8532e-01, -1.4186e-01, -2.3342e-01, -1.0725e-01,\n",
      "          8.1047e-02, -2.1209e-01,  9.2952e-01,  6.6443e-01, -3.4321e-01,\n",
      "         -5.2666e-01, -1.3863e+00,  8.5520e-02,  6.1834e-01,  1.9319e-02,\n",
      "         -7.3439e-01,  7.6363e-01, -5.7546e-01,  6.1356e-01, -4.3227e-01,\n",
      "         -7.1897e-01,  4.5112e-01, -1.6110e-01,  7.3366e-01,  1.1173e+00,\n",
      "          4.5399e-01,  3.6378e-01, -3.3999e-01, -2.1627e-01, -1.0385e-01,\n",
      "         -8.9007e-01, -3.0824e-01, -9.1451e-01, -4.2192e-01,  1.4248e+00,\n",
      "          9.6088e-01,  1.0333e+00, -4.4413e-01, -6.9713e-01, -5.5990e-01,\n",
      "          1.3893e-01,  4.1954e-02,  5.2935e-02,  4.9384e-01, -3.1910e-01,\n",
      "          5.7452e-01,  8.2277e-01,  1.5875e+00,  3.5637e-01, -8.6354e-01,\n",
      "          1.8259e+00, -7.9525e-01,  7.1993e-01, -2.3062e-01, -7.6430e-01,\n",
      "         -2.2603e-01,  3.2128e-02,  1.1410e+00, -5.6189e-01, -2.5896e-01,\n",
      "          2.9211e-01, -4.7965e-01, -1.1395e+00,  4.8355e-01, -1.6805e+00,\n",
      "          4.7103e-01, -1.8938e+01,  1.7601e-01, -2.5785e-01,  2.2375e-01,\n",
      "         -1.2240e+00,  8.2005e-01,  5.1712e-01, -4.8107e-01, -3.1526e-01,\n",
      "         -4.1174e-01,  3.3303e-01, -8.3551e-01,  1.1646e+00,  7.6988e-01,\n",
      "          8.1081e-01,  9.0155e-02,  1.2480e+00, -1.4755e+00, -3.4817e-01,\n",
      "          9.1426e-01, -6.8838e-01,  2.0128e+00,  2.7206e+00, -2.0203e+00,\n",
      "         -1.6559e-01,  2.5782e-01, -1.3978e-01, -7.4225e-01, -1.1708e-01,\n",
      "          2.1820e-01,  4.3943e-01, -5.6162e-01,  8.3140e-01,  1.1036e-01,\n",
      "          7.1410e-01,  1.0955e+00,  1.1616e-01,  1.7659e-01,  3.4367e-02,\n",
      "          9.6717e-01,  1.0753e+00,  6.7046e-01, -4.3192e-01,  7.2326e-01,\n",
      "          2.5141e-01, -2.2617e+00,  1.0139e-02, -2.6588e-01, -1.9670e+00,\n",
      "         -1.0899e+00,  2.6502e-01,  1.3044e+00,  7.8144e-01, -4.6978e-01,\n",
      "         -1.2560e+00,  8.5386e-01,  3.7708e-01,  2.5417e-01, -4.2650e-01,\n",
      "          1.6555e-01,  8.3346e+00, -3.9528e-01, -2.1504e-01, -9.2097e-02,\n",
      "          2.3149e-01,  1.3310e+00,  7.0082e-02, -8.4705e-01, -4.6206e-01,\n",
      "         -1.2079e+00, -8.9597e-01,  1.3533e+00, -1.5666e-02, -6.6770e-01,\n",
      "         -1.0470e+00,  1.6439e-01,  1.2748e-01, -1.1479e+00,  2.3659e-01,\n",
      "          2.7071e-02, -1.0349e+00, -4.3282e-01, -2.3760e-01,  7.9156e-01,\n",
      "          3.4175e-01,  9.3465e-01,  1.0331e+00,  1.1616e-01,  5.0146e-01,\n",
      "          2.4077e-01,  3.1130e-01,  2.2578e-01,  2.1273e-01,  5.4313e-01,\n",
      "          1.3754e+00,  2.4638e-01,  7.5503e-02, -4.4343e-03, -3.5243e-01,\n",
      "         -3.4774e-01,  2.1911e-01, -2.4734e-01, -3.5272e-02, -5.5294e-01,\n",
      "          4.8605e-02,  3.1193e-01, -9.8921e-01, -1.8223e+01,  1.6140e-01,\n",
      "         -1.5386e+00,  9.7059e-01,  1.3865e+00,  1.2798e+00,  1.7177e-01,\n",
      "          7.0927e-01,  3.9713e-01,  1.5053e+00,  6.8940e-01, -4.9052e-01,\n",
      "          3.8528e-01, -2.4243e-01,  6.8248e-01, -6.2394e-01, -4.4412e-01,\n",
      "         -4.0510e-01,  1.0674e+00,  2.8894e-01,  1.2964e+01, -2.9318e-01,\n",
      "         -2.1687e-01, -6.8564e-01, -7.3402e-03,  1.0724e-01, -2.5287e-01,\n",
      "         -1.0361e-01,  6.0103e-01,  1.5218e-01,  2.3297e-01, -4.6359e-01,\n",
      "          4.4128e-01,  6.0403e-01,  1.4095e+00,  1.0736e+00, -4.0920e-01,\n",
      "         -1.8461e-01,  1.4554e+00, -2.1110e-01, -2.8839e-01, -5.8783e-01,\n",
      "          1.3412e+00,  6.8006e-01, -1.0073e-02, -3.7402e-01, -1.9396e-01,\n",
      "          4.5272e-01,  1.4306e+00, -1.3579e+00, -4.0258e-01, -3.4477e-01,\n",
      "         -5.2761e-01,  1.0667e+00, -5.1301e-01, -7.2965e-01, -6.1291e-01,\n",
      "          2.0216e+00, -5.4553e-01, -6.2227e-01,  1.4082e-01, -5.7183e-01,\n",
      "         -8.5880e-01, -7.4163e-01, -2.2211e-01,  1.1312e+00,  1.0559e+00,\n",
      "         -6.2348e-02, -9.0769e-02, -3.9481e-01, -3.8349e-01, -8.9987e-01,\n",
      "          1.0083e-01, -4.8833e-01,  2.9407e+01, -1.0739e+00, -6.7318e-01,\n",
      "         -4.3835e-01, -8.3817e-01,  3.7533e-01, -8.3060e-01, -8.3203e-02,\n",
      "          8.7362e-01,  5.7471e-01,  7.7126e-01,  6.1508e-01, -2.9867e+00,\n",
      "         -9.5177e-01,  2.6956e-01, -3.1108e-01, -4.8536e-02, -8.6215e-01,\n",
      "         -1.5912e+00,  3.9042e-02,  1.1449e-01, -4.6302e-01, -1.9135e-01,\n",
      "         -6.3536e-01, -1.8149e-01,  4.5963e-02, -2.3739e-01, -5.3759e-01,\n",
      "         -2.1863e-01,  1.8557e-01,  1.1646e+00,  3.5019e-01, -8.3335e-01,\n",
      "          1.6261e+01,  5.3977e+00, -2.5283e-01, -2.0614e-01, -3.9275e-01,\n",
      "          5.6286e-01, -1.1281e-01,  1.0479e-01, -8.4611e-01,  1.3391e+00,\n",
      "         -7.0234e-01, -7.5649e-01,  4.4704e-01, -5.5709e-01, -6.3910e-01,\n",
      "          1.1870e+00,  1.0606e-01, -1.1814e+00,  5.3204e-01,  5.7642e-01,\n",
      "         -1.5433e-01, -3.2132e-01,  6.6358e-01, -4.6960e-01, -7.6055e-01,\n",
      "         -1.8587e-02,  1.3065e-01,  1.5878e-01,  1.0918e+00,  1.5208e-01,\n",
      "         -1.5418e+00, -4.5894e-01, -2.7236e-01,  2.3603e-01, -1.3936e+00,\n",
      "         -3.3544e-01,  3.6059e-01,  2.3139e-01, -1.5134e-01,  2.2449e-01,\n",
      "          1.0922e-01, -1.6298e+00, -9.5859e-02,  1.9319e-01,  1.3244e-01,\n",
      "         -4.2666e-02, -3.3745e+00,  3.7083e-01,  5.2789e-01, -9.2180e-01,\n",
      "         -1.3047e-01,  1.6862e-01,  1.0391e-01, -7.4411e-02, -6.4847e-01,\n",
      "          2.7789e-01,  2.2855e-01, -6.0301e-01,  1.4309e+00,  5.3966e-01,\n",
      "          4.4953e-01,  3.0890e-01, -8.9442e-01,  8.8827e-01, -1.8488e-01,\n",
      "          5.8172e-01,  3.1613e-02, -7.2688e-01, -1.9623e+00, -5.7789e-01,\n",
      "          8.9684e-01,  6.6931e-01,  4.8683e-01, -2.7698e-01, -4.7970e-01,\n",
      "         -5.0896e-02, -2.7301e-01,  1.0621e-01,  3.1207e-01, -4.7809e-01,\n",
      "         -5.8412e-01, -9.0995e-01,  4.6229e-01, -5.8160e-01,  4.4373e-01,\n",
      "         -8.6644e-01,  1.0206e+00,  6.1937e-01,  1.7609e-01,  5.8833e-02,\n",
      "          7.7658e-01,  2.0856e-01,  7.1197e-02, -1.1246e+00,  3.8542e-01,\n",
      "          1.0427e+00, -5.9923e-01, -9.9469e-02, -6.7835e-01, -4.9267e-02,\n",
      "          8.1965e-01,  4.2742e-01,  2.0667e-01,  1.8200e-01,  8.5722e-01,\n",
      "          3.7348e-01, -9.8361e-02,  6.5404e-01, -6.5917e-01, -9.2415e-03,\n",
      "         -2.0296e-01, -5.2105e-01, -1.3144e-01, -4.2311e-01, -7.8123e-02,\n",
      "          5.5325e-01, -1.6342e+00,  4.5289e-01, -8.1301e-02, -6.0304e-01,\n",
      "         -4.1680e-01, -5.9837e-02, -2.8189e-01,  6.1218e-01, -1.3354e-01,\n",
      "         -3.9834e-01,  4.5478e-01, -4.6718e-01,  1.2451e+00,  1.4399e+00,\n",
      "         -1.2275e+00, -9.8002e-01,  1.3498e-01, -7.1976e-01,  3.1686e-02,\n",
      "         -1.0718e-01,  6.3502e-01,  6.8600e-01, -3.7529e-01, -1.1433e-01,\n",
      "         -6.7633e-01, -7.7607e-01,  9.7386e-02, -6.8410e-01,  1.7581e+00,\n",
      "         -2.9491e-01,  1.0594e+00,  4.9720e-01,  2.4445e-01, -5.7586e-01,\n",
      "          2.7067e-01, -3.3353e-01,  2.7007e-01,  6.7721e-01, -4.1382e-02,\n",
      "         -1.0934e+00, -1.2809e-01, -5.4838e-01, -1.5855e-01,  7.6948e-01,\n",
      "          3.7078e+00,  9.6895e-01, -2.3653e-01,  6.5033e-01,  2.9770e-01,\n",
      "         -2.8502e-01,  3.1783e-01, -7.0752e-01,  2.9552e-01, -1.8143e+00,\n",
      "         -2.4141e-01,  8.3160e-01, -2.8419e-01,  1.7206e-01,  3.7636e-02,\n",
      "         -1.2047e+00,  4.8058e-01, -2.7040e-01,  3.2063e-01, -1.5217e+00,\n",
      "         -2.0032e-01, -2.4451e-01,  5.2312e-02,  1.4995e-01, -9.2914e-01,\n",
      "          8.6020e-01,  7.0874e-01,  3.1957e-01,  1.4211e-02,  1.7135e-01,\n",
      "          2.8176e-01,  6.3573e-01, -3.6138e-01,  4.6184e-01,  2.3291e-01,\n",
      "          4.2502e-01,  5.3387e-01,  1.1593e-01,  1.2511e+00,  5.0307e+00,\n",
      "         -2.3220e-01, -9.0139e-01,  6.3643e-01, -2.0155e-01,  1.0010e+00,\n",
      "          1.3253e-01, -2.6072e-01, -6.2005e-01,  1.2560e+00,  6.9893e-01,\n",
      "         -1.2042e+00, -7.3748e-02, -1.4664e-01,  9.9471e-01, -2.7344e-04,\n",
      "         -2.8009e-01,  7.6223e-01,  8.0120e-01,  9.1941e-01, -4.7056e-01,\n",
      "         -2.3850e-01,  2.2041e-01,  4.1831e-02, -9.7497e-01,  2.3409e-01,\n",
      "          6.7090e-01,  1.0729e+00,  6.6003e-01, -2.2521e-01,  5.0784e-02,\n",
      "          5.5511e-01, -1.5086e+00, -7.3922e-01, -8.3750e-01, -9.3624e-01,\n",
      "          2.4753e-01, -1.1211e-01, -5.8098e-01,  1.8132e+00, -1.2676e+00,\n",
      "         -1.1011e-01, -8.9572e-01, -6.2645e-02, -9.1870e-01,  1.2664e+00,\n",
      "          3.1482e-01, -1.0641e-01, -1.0259e+00, -3.4291e-01,  5.6939e-01,\n",
      "          8.4247e-01, -5.8301e-01, -2.7896e-01,  3.8400e-01,  3.8772e-01,\n",
      "         -2.8529e-01, -3.6026e-01,  4.8741e-01,  1.5510e-01, -6.3369e-01,\n",
      "         -7.0015e-01,  9.4550e-02, -8.0294e-01,  1.0912e-01,  4.9197e-01,\n",
      "         -1.3009e+00, -3.2552e-01, -4.8459e-01, -1.1705e+00, -7.3087e-01,\n",
      "          9.2088e-02,  4.4461e-01, -1.0484e+00,  2.9514e-02,  3.2511e-01,\n",
      "         -1.2804e+00, -4.3199e-01, -2.7469e-01,  7.7575e-03,  2.9492e-01,\n",
      "          1.3216e-01,  1.0791e+00,  1.4663e+00,  6.7046e-01,  2.2797e-01,\n",
      "          2.6942e-02,  5.5614e-01, -1.4679e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(response_avg_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
